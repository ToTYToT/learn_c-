--------1.搜索引擎
        两个阶段
            离线部分
                网络爬虫 --> 网页集合 --> 网页库 --> 索引

                >创建网页库
                >网页去重 算法?
                    如何判断去重?(两篇文章相同) 相似特征 阈值
                    词频统计,前二十个词的词频统计(cppjieba)(NLPIR)
                    a,先获取每篇文章中的词频最高的前二十个词,假定这20个词是能代表这篇文章的,此时,比较
                    两篇文章中的前二十个词有十五个是相同的,就认定这两篇文章是相同的
                    b.LCS(最长公共子序列)
                >建立倒排索引库
                以关键词为索引,每个关键词存储所被包含的文章,
                关键词,文章,词频,总词频,网页排序,权重词,
                关键词 某个词在文章中出现的次数 term frequency
                document frequency ,某个词在文章中出现的次数(包含该词的文档数)(辨识度)
                idf: inverse document frequency,逆文档频率,表示该词对于该篇文章的重要性的一个系数

                idf = log(N/df) -------------- N 表示文档中的总数

                词的特征权重(该词对于该篇文章的重要性)的计算:
                    W = tf * idf
                    然后要进行归一化处理:
                        W' = W / sqrt(w1^2 + w2^2 + ... wn^2)
                        W'是真正需要的权重值
                        


            在线部分
                通过浏览器,提供查询关键字(获取关键字!!!)
                    将关键字看做一篇文档,权重值,计算出关键字的权重值weight(W')
                服务器获取到查询关键字,并通过倒排索引在网页库中进行查找,
                    找到文章后,开始摘要,获取文章
                    <标题>
                    <URL>
                    <摘要>
                    要根据不同的查询关键字自动生成
                    对多篇文章进行排序(排序算法 --> 余弦相似度计算)
                发送数据时,要通过json格式打包数据(jsoncpp)

                如果能查找到相关信息,再把查询结果通过网络发送给客户端

                实时搜索

            优化功能:
                添加缓存系统
                    自己实现
                    redis/memcached


